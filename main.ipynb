{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to dataset: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from itertools import product\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import joblib\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset already split into test, train and val. However, we want to try and do our own data splits. Therefore, merge the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './archive/'\n",
    "filenames = ['test.txt', 'train.txt', 'val.txt']\n",
    "\n",
    "if not os.path.exists('all.csv'):\n",
    "    # Combine all the files into one csv file\n",
    "    with open('all.csv', 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=';')\n",
    "        writer.writerow(['text', 'label'])\n",
    "\n",
    "        for fname in filenames:\n",
    "            with open(path + fname) as infile:\n",
    "                for line in infile:\n",
    "                    # Split the line into text and label using the semicolon\n",
    "                    text, label = line.strip().split(';')\n",
    "                    writer.writerow([text, label])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  im feeling rather rotten so im not very ambiti...  sadness\n",
       "1          im updating my blog because i feel shitty  sadness\n",
       "2  i never make her separate from me because i do...  sadness\n",
       "3  i left with my bouquet of red and yellow tulip...      joy\n",
       "4    i was feeling a little vain when i did this one  sadness"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and len(token) > 1]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words and lemmatize from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('processed.csv'):\n",
    "    # Split the text into tokens\n",
    "    df['text'] = df['text'].apply(process_text)\n",
    "    df.to_csv('processed.csv', index=False)\n",
    "else:\n",
    "    df = pd.read_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['sadness' 'joy' 'fear' 'anger' 'love' 'surprise']\n",
      "Instances of each category:\n",
      "sadness: 5797\n",
      "joy: 6761\n",
      "fear: 2373\n",
      "anger: 2709\n",
      "love: 1641\n",
      "surprise: 719\n"
     ]
    }
   ],
   "source": [
    "print(f'Categories: {df[\"label\"].unique()}')\n",
    "print('Instances of each category:')\n",
    "for label in df['label'].unique():\n",
    "    print(f'{label}: {len(df[df[\"label\"] == label])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map labels to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel rotten ambitious right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update blog feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>separate not want feel like ashamed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave bouquet red yellow tulip arm feel slight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel little vain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                        feel rotten ambitious right      0\n",
       "1                            update blog feel shitty      0\n",
       "2                separate not want feel like ashamed      0\n",
       "3  leave bouquet red yellow tulip arm feel slight...      1\n",
       "4                                   feel little vain      0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    'sadness': 0,\n",
    "    'joy': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'love': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: mapping[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test. Do random oversampling to reduce categorical imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = len(df['label'].unique())\n",
    "# Split the data into training and testing data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared function for evaluating performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate best combined score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_score(reports):\n",
    "    total_score = 0\n",
    "    for report in reports:\n",
    "        # Calculate the combined score of precision, recall and f1-score\n",
    "        precision = report['weighted avg']['precision']\n",
    "        recall = report['weighted avg']['recall']\n",
    "        f1_score = report['weighted avg']['f1-score']\n",
    "        accuracy = report['accuracy']\n",
    "        total_score += (2 * precision + recall + 2 * f1_score + accuracy) / 6\n",
    "    \n",
    "    return total_score / len(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate model using K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kfold(model, train_df):\n",
    "    splits = 5\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1)\n",
    "    reports = []\n",
    "    for i, (train_i, test_i) in enumerate(skf.split(train_df['text'], train_df['label'])):\n",
    "        text_train, text_validation = train_df['text'][train_i], train_df['text'][test_i]\n",
    "        label_train, label_validation = train_df['label'][train_i], train_df['label'][test_i]\n",
    "        \n",
    "        ros = RandomOverSampler(random_state=1)\n",
    "        text_train, label_train = ros.fit_resample(text_train.values.reshape(-1, 1), label_train)\n",
    "        text_train = text_train.flatten()\n",
    "        \n",
    "        # Create the model and train\n",
    "        model.fit(text_train, label_train)\n",
    "        \n",
    "        # Evaluate the model on validation then test data\n",
    "        report = classification_report(label_validation, model.predict(text_validation), output_dict=True, zero_division=0)\n",
    "        reports.append(report)\n",
    "    return combined_score(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build model based on input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_nb(max_features, ngram_range, alpha, smooth_df, max_df, norm):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features,\n",
    "                                ngram_range=ngram_range,\n",
    "                                smooth_idf=smooth_df,\n",
    "                                max_df=max_df,\n",
    "                                norm=norm)\n",
    "    classifier = MultinomialNB(alpha=alpha)\n",
    "    return Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search using K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8522843711801421\n",
      "Best params: {'max_features': None, 'ngram_range': (1, 2), 'alpha': 0.5, 'smooth_df': True, 'max_df': 0.25, 'norm': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidf__max_features': [100, 500, 1000, 2000, None],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__alpha': [0.1, 0.5, 1, 2],\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "    'tfidf__norm': ('l1', 'l2', None),\n",
    "}\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for max_features, ngram_range, alpha, tfidf__smooth_idf, tfidf__max_df, tfidf__norm in param_combinations:\n",
    "    model = build_model_nb(max_features=max_features, \n",
    "                            ngram_range=ngram_range, \n",
    "                            alpha=alpha, \n",
    "                            smooth_df=tfidf__smooth_idf, \n",
    "                            max_df=tfidf__max_df, \n",
    "                            norm=tfidf__norm)\n",
    "    score = evaluate_kfold(model, train_df)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'max_features': max_features,\n",
    "            'ngram_range': ngram_range,\n",
    "            'alpha': alpha,\n",
    "            'smooth_df': tfidf__smooth_idf,\n",
    "            'max_df': tfidf__max_df,\n",
    "            'norm': tfidf__norm\n",
    "        }\n",
    "\n",
    "print(f'Best score: {best_score}')\n",
    "print(f'Best params: {best_params}')\n",
    "with open('naive_bayes_best_parameters', 'w') as f:\n",
    "    f.write(str(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      1146\n",
      "           1       0.92      0.85      0.89      1343\n",
      "           2       0.79      0.81      0.80       475\n",
      "           3       0.84      0.85      0.85       529\n",
      "           4       0.68      0.79      0.73       356\n",
      "           5       0.51      0.78      0.62       151\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.78      0.83      0.79      4000\n",
      "weighted avg       0.86      0.84      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_train, label_train = train_df['text'], train_df['label']\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "text_train, label_train = ros.fit_resample(text_train.values.reshape(-1, 1), label_train)\n",
    "text_train = text_train.flatten()\n",
    "\n",
    "model = build_model_nb(max_features=None,\n",
    "                    ngram_range=(1, 2),\n",
    "                    alpha=0.5,\n",
    "                    smooth_df=True,\n",
    "                    max_df=0.25,\n",
    "                    norm='l2')\n",
    "\n",
    "# Create the model and train on entire training data\n",
    "model.fit(text_train, label_train)\n",
    "joblib.dump(model, 'naive_bayes.pkl')\n",
    "print(classification_report(test_df['label'], model.predict(test_df['text']), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(text):\n",
    "    emotions = ['sadness', 'joy', 'fear', 'anger', 'love', 'surprise']\n",
    "    # Load the model\n",
    "    model = joblib.load('naive_bayes.pkl')\n",
    "    processed_text = process_text(text)\n",
    "    prediction = model.predict([processed_text])\n",
    "    return emotions[prediction[0]]\n",
    "\n",
    "print(naive_bayes('Charles are you fluent in jappanese?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build model based on input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lr(solver, C, multi_class, tol, max_df, norm):\n",
    "    vectorizer = TfidfVectorizer(max_features=None,\n",
    "                                ngram_range=(1, 2),\n",
    "                                smooth_idf=True,\n",
    "                                max_df=max_df,\n",
    "                                norm=norm,)\n",
    "    classifier = LogisticRegression(solver=solver,\n",
    "                                    C=C,\n",
    "                                    multi_class=multi_class,\n",
    "                                    tol=tol,\n",
    "                                    max_iter=500)\n",
    "    return Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search using K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8921059859048593\n",
      "Best params: {'max_df': 1.0, 'norm': 'l2', 'solver': 'saga', 'C': 10, 'multi_class': 'ovr', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'tfidf__max_df': [0.25, 0.5, 1.0],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'clf__solver': ['newton-cg', 'sag', 'saga'],\n",
    "    'clf__C': [1, 10],\n",
    "    'clf__multi_class': ['ovr', 'multinomial'],\n",
    "    'clf__tol': [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for tfidf__max_df, tfidf__norm, clf__solver, clf__C, clf__multi_class, clf__tol in param_combinations:\n",
    "    model = build_model_lr(max_df=tfidf__max_df,\n",
    "                            norm=tfidf__norm,\n",
    "                            solver=clf__solver,\n",
    "                            C=clf__C,\n",
    "                            multi_class=clf__multi_class,\n",
    "                            tol=clf__tol)\n",
    "    score = evaluate_kfold(model, train_df)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'max_df': tfidf__max_df,\n",
    "            'norm': tfidf__norm,\n",
    "            'solver': clf__solver,\n",
    "            'C': clf__C,\n",
    "            'multi_class': clf__multi_class,\n",
    "            'tol': clf__tol,\n",
    "        }\n",
    "        with open('logistic_regression_best_parameters', 'w') as f:\n",
    "            f.write(str(best_params))\n",
    "\n",
    "print(f'Best score: {best_score}')\n",
    "print(f'Best params: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1146\n",
      "           1       0.93      0.92      0.92      1343\n",
      "           2       0.87      0.84      0.85       475\n",
      "           3       0.92      0.90      0.91       529\n",
      "           4       0.79      0.83      0.81       356\n",
      "           5       0.68      0.82      0.74       151\n",
      "\n",
      "    accuracy                           0.90      4000\n",
      "   macro avg       0.85      0.87      0.86      4000\n",
      "weighted avg       0.90      0.90      0.90      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_train, label_train = train_df['text'], train_df['label']\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "text_train, label_train = ros.fit_resample(text_train.values.reshape(-1, 1), label_train)\n",
    "text_train = text_train.flatten()\n",
    "\n",
    "model = build_model_lr(solver='saga',\n",
    "                        C=10,\n",
    "                        multi_class='ovr',\n",
    "                        tol=0.01,\n",
    "                        max_df=1.0,\n",
    "                        norm='l2')\n",
    "                        \n",
    "# Create the model and train on entire training data\n",
    "model.fit(text_train, label_train)\n",
    "joblib.dump(model, 'logistic_regression.pkl')\n",
    "print(classification_report(test_df['label'], model.predict(test_df['text']), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run the model on a given piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_regression(text):\n",
    "    emotions = ['sadness', 'joy', 'fear', 'anger', 'love', 'surprise']\n",
    "    # Load the model\n",
    "    model = joblib.load('naive_bayes.pkl')\n",
    "    processed_text = process_text(text)\n",
    "    prediction = model.predict([processed_text])\n",
    "    return emotions[prediction[0]]\n",
    "\n",
    "logistic_regression(\"Charles are you fluent in janpanese?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
