{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to dataset: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TextVectorization, Dropout\n",
    "from keras.metrics import AUC, CategoricalAccuracy\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset already split into test, train and val. However, we want to try and do our own data splits. Therefore, merge the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './archive/'\n",
    "filenames = ['test.txt', 'train.txt', 'val.txt']\n",
    "\n",
    "if not os.path.exists('all.csv'):\n",
    "    # Combine all the files into one csv file\n",
    "    with open('all.csv', 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=';')\n",
    "        writer.writerow(['text', 'label'])\n",
    "\n",
    "        for fname in filenames:\n",
    "            with open(path + fname) as infile:\n",
    "                for line in infile:\n",
    "                    # Split the line into text and label using the semicolon\n",
    "                    text, label = line.strip().split(';')\n",
    "                    writer.writerow([text, label])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  im feeling rather rotten so im not very ambiti...  sadness\n",
       "1          im updating my blog because i feel shitty  sadness\n",
       "2  i never make her separate from me because i do...  sadness\n",
       "3  i left with my bouquet of red and yellow tulip...      joy\n",
       "4    i was feeling a little vain when i did this one  sadness"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and len(token) > 1]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words and lemmatize from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('processed.csv'):\n",
    "    # Split the text into tokens\n",
    "    df['text'] = df['text'].apply(process_text)\n",
    "    df.to_csv('processed.csv', index=False)\n",
    "else:\n",
    "    df = pd.read_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['sadness' 'joy' 'fear' 'anger' 'love' 'surprise']\n",
      "Instances of each category:\n",
      "sadness: 5797\n",
      "joy: 6761\n",
      "fear: 2373\n",
      "anger: 2709\n",
      "love: 1641\n",
      "surprise: 719\n"
     ]
    }
   ],
   "source": [
    "print(f'Categories: {df[\"label\"].unique()}')\n",
    "print('Instances of each category:')\n",
    "for label in df['label'].unique():\n",
    "    print(f'{label}: {len(df[df[\"label\"] == label])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map labels to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel rotten ambitious right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update blog feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>separate not want feel like ashamed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave bouquet red yellow tulip arm feel slight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel little vain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                        feel rotten ambitious right      0\n",
       "1                            update blog feel shitty      0\n",
       "2                separate not want feel like ashamed      0\n",
       "3  leave bouquet red yellow tulip arm feel slight...      1\n",
       "4                                   feel little vain      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    'sadness': 0,\n",
    "    'joy': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'love': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: mapping[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test. Do random oversampling to reduce categorical imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = len(df['label'].unique())\n",
    "# Split the data into training and testing data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "x = train_df['text']\n",
    "y = train_df['label']\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "x_resampled, y_resampled = ros.fit_resample(x.values.reshape(-1, 1), y)\n",
    "train_df = pd.concat([pd.DataFrame(x_resampled, columns=['text']), pd.DataFrame(y_resampled, columns=['label'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to do one-hot encoding for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(label):\n",
    "    return tf.keras.utils.to_categorical(label, num_classes=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K-Fold split and train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# Code from https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "#########################################################################################\n",
    "\n",
    "# Prepare the test data\n",
    "text_test = test_df['text']\n",
    "label_test = test_df['label'].apply(to_categorical)\n",
    "label_test = tf.convert_to_tensor(label_test.values.tolist())\n",
    "\n",
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1)\n",
    "best_accuracy = 0\n",
    "for i, (train_i, test_i) in enumerate(skf.split(train_df['text'], train_df['label'])):\n",
    "    print(f'Fold {i+1}')\n",
    "    text_train, text_validation = train_df['text'][train_i], train_df['text'][test_i]\n",
    "    label_train, label_validation = train_df['label'][train_i], train_df['label'][test_i]\n",
    "\n",
    "    # Encode labels with one-hot encoding\n",
    "    label_train = label_train.apply(to_categorical)\n",
    "    label_validation = label_validation.apply(to_categorical)\n",
    "    \n",
    "    # Convert labels to tensors\n",
    "    label_train = tf.convert_to_tensor(label_train.values.tolist())\n",
    "    label_validation = tf.convert_to_tensor(label_validation.values.tolist())\n",
    "    \n",
    "    # Create vectorization layer\n",
    "    vectorize_layer = TextVectorization(output_mode='tf-idf')\n",
    "    training_data = tf.convert_to_tensor(text_train.values.tolist())\n",
    "    vectorize_layer.adapt(training_data)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(vectorize_layer)\n",
    "    model.add(Dense(units=num_of_classes,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "                    activation='softmax'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[CategoricalAccuracy(name='Accuracy'), AUC(multi_label=True, name='AUC'), f1_m, precision_m, recall_m])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(text_train, label_train, batch_size=64, epochs=10, verbose=1)\n",
    "    \n",
    "    # Evaluate the model on validation then test data\n",
    "    print('Validation:')\n",
    "    model.evaluate(text_validation, label_validation)\n",
    "    \n",
    "    print('Test:')\n",
    "    _, accuracy, _, _, _, _ = model.evaluate(text_test, label_test)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        model.save('logistic_regression_model.keras')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run the model on a given piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_regression(text):\n",
    "    emotions = ['sadness', 'joy', 'fear', 'anger', 'love', 'surprise']\n",
    "    # Load the model\n",
    "    custom_objects = {\"f1_m\": f1_m, \"precision_m\": precision_m, \"recall_m\": recall_m}\n",
    "    model = tf.keras.models.load_model('./logistic_regression_model.keras', custom_objects=custom_objects)\n",
    "    processed_text = process_text(text)\n",
    "    prediction = model.predict([processed_text])\n",
    "    prediction = np.argmax(prediction)\n",
    "    return emotions[prediction]\n",
    "\n",
    "logistic_regression(\"im feeling a little cranky negative after this doctors appointment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
