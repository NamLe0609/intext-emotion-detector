{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to dataset: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 00:31:29.952778: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-13 00:31:29.952841: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-13 00:31:30.009102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-13 00:31:30.123785: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-13 00:31:31.404792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset already split into test, train and val. However, we want to try and do our own data splits. Therefore, merge the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './archive/'\n",
    "filenames = ['test.txt', 'train.txt', 'val.txt']\n",
    "\n",
    "if not os.path.exists('all.csv'):\n",
    "    # Combine all the files into one csv file\n",
    "    with open('all.csv', 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=';')\n",
    "        writer.writerow(['text', 'label'])\n",
    "\n",
    "        for fname in filenames:\n",
    "            with open(path + fname) as infile:\n",
    "                for line in infile:\n",
    "                    # Split the line into text and label using the semicolon\n",
    "                    text, label = line.strip().split(';')\n",
    "                    writer.writerow([text, label])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  im feeling rather rotten so im not very ambiti...  sadness\n",
       "1          im updating my blog because i feel shitty  sadness\n",
       "2  i never make her separate from me because i do...  sadness\n",
       "3  i left with my bouquet of red and yellow tulip...      joy\n",
       "4    i was feeling a little vain when i did this one  sadness"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and len(token) > 1]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words and lemmatize from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('processed.csv'):\n",
    "    # Split the text into tokens\n",
    "    df['text'] = df['text'].apply(process_text)\n",
    "    df.to_csv('processed.csv', index=False)\n",
    "else:\n",
    "    df = pd.read_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show statistics about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['sadness' 'joy' 'fear' 'anger' 'love' 'surprise']\n",
      "Instances of each category:\n",
      "sadness: 5797\n",
      "joy: 6761\n",
      "fear: 2373\n",
      "anger: 2709\n",
      "love: 1641\n",
      "surprise: 719\n"
     ]
    }
   ],
   "source": [
    "print(f'Categories: {df[\"label\"].unique()}')\n",
    "print('Instances of each category:')\n",
    "for label in df['label'].unique():\n",
    "    print(f'{label}: {len(df[df[\"label\"] == label])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map labels to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel rotten ambitious right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update blog feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>separate not want feel like ashamed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave bouquet red yellow tulip arm feel slight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel little vain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                        feel rotten ambitious right      0\n",
       "1                            update blog feel shitty      0\n",
       "2                separate not want feel like ashamed      0\n",
       "3  leave bouquet red yellow tulip arm feel slight...      1\n",
       "4                                   feel little vain      0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    'sadness': 0,\n",
    "    'joy': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'love': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: mapping[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test. Do random oversampling to reduce categorical imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = len(df['label'].unique())\n",
    "# Split the data into training and testing data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K-Fold split and train naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.85       930\n",
      "           1       0.91      0.80      0.85      1084\n",
      "           2       0.71      0.76      0.74       379\n",
      "           3       0.74      0.80      0.77       436\n",
      "           4       0.59      0.77      0.67       257\n",
      "           5       0.42      0.72      0.53       114\n",
      "\n",
      "    accuracy                           0.79      3200\n",
      "   macro avg       0.71      0.78      0.73      3200\n",
      "weighted avg       0.82      0.79      0.80      3200\n",
      "\n",
      "Fold 2 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85       930\n",
      "           1       0.92      0.79      0.85      1084\n",
      "           2       0.70      0.76      0.73       379\n",
      "           3       0.79      0.83      0.81       436\n",
      "           4       0.56      0.80      0.66       257\n",
      "           5       0.45      0.80      0.57       114\n",
      "\n",
      "    accuracy                           0.80      3200\n",
      "   macro avg       0.72      0.80      0.74      3200\n",
      "weighted avg       0.83      0.80      0.80      3200\n",
      "\n",
      "Fold 3 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       930\n",
      "           1       0.90      0.80      0.85      1084\n",
      "           2       0.71      0.82      0.76       380\n",
      "           3       0.81      0.79      0.80       436\n",
      "           4       0.57      0.76      0.65       257\n",
      "           5       0.47      0.73      0.57       113\n",
      "\n",
      "    accuracy                           0.81      3200\n",
      "   macro avg       0.73      0.79      0.75      3200\n",
      "weighted avg       0.83      0.81      0.81      3200\n",
      "\n",
      "Fold 4 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       931\n",
      "           1       0.90      0.82      0.86      1083\n",
      "           2       0.76      0.78      0.77       380\n",
      "           3       0.78      0.85      0.81       436\n",
      "           4       0.60      0.70      0.65       257\n",
      "           5       0.44      0.68      0.54       113\n",
      "\n",
      "    accuracy                           0.81      3200\n",
      "   macro avg       0.73      0.78      0.75      3200\n",
      "weighted avg       0.82      0.81      0.81      3200\n",
      "\n",
      "Fold 5 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86       930\n",
      "           1       0.91      0.79      0.85      1083\n",
      "           2       0.75      0.79      0.77       380\n",
      "           3       0.77      0.79      0.78       436\n",
      "           4       0.60      0.80      0.68       257\n",
      "           5       0.42      0.69      0.52       114\n",
      "\n",
      "    accuracy                           0.80      3200\n",
      "   macro avg       0.72      0.78      0.74      3200\n",
      "weighted avg       0.82      0.80      0.81      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1)\n",
    "best_accuracy = 0\n",
    "for i, (train_i, test_i) in enumerate(skf.split(train_df['text'], train_df['label'])):\n",
    "    text_train, text_validation = train_df['text'][train_i], train_df['text'][test_i]\n",
    "    label_train, label_validation = train_df['label'][train_i], train_df['label'][test_i]\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    text_train, label_train = ros.fit_resample(text_train.values.reshape(-1, 1), label_train)\n",
    "    text_train = text_train.flatten()\n",
    "    \n",
    "    # Create the model and train\n",
    "    naive_bayes = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "    naive_bayes.fit(text_train, label_train)\n",
    "    \n",
    "    # Evaluate the model on validation then test data\n",
    "    print(f\"Fold {i+1} validation:\")\n",
    "    print(classification_report(label_validation, naive_bayes.predict(text_validation)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K-Fold split to evaluate the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 1 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      1083\n",
      "           1       0.94      0.89      0.91      1084\n",
      "           2       0.96      0.94      0.95      1084\n",
      "           3       0.95      0.96      0.95      1084\n",
      "           4       0.92      0.98      0.95      1084\n",
      "           5       0.96      1.00      0.98      1083\n",
      "\n",
      "    accuracy                           0.94      6502\n",
      "   macro avg       0.94      0.94      0.94      6502\n",
      "weighted avg       0.94      0.94      0.94      6502\n",
      "\n",
      "Fold 1 test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      1146\n",
      "           1       0.92      0.88      0.90      1343\n",
      "           2       0.84      0.84      0.84       475\n",
      "           3       0.88      0.87      0.87       529\n",
      "           4       0.75      0.84      0.79       356\n",
      "           5       0.64      0.85      0.73       151\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.82      0.86      0.84      4000\n",
      "weighted avg       0.88      0.87      0.88      4000\n",
      "\n",
      "Fold 2\n",
      "Fold 2 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1084\n",
      "           1       0.94      0.88      0.91      1083\n",
      "           2       0.95      0.92      0.94      1084\n",
      "           3       0.95      0.96      0.95      1084\n",
      "           4       0.91      0.96      0.94      1084\n",
      "           5       0.95      1.00      0.98      1083\n",
      "\n",
      "    accuracy                           0.94      6502\n",
      "   macro avg       0.94      0.94      0.94      6502\n",
      "weighted avg       0.94      0.94      0.94      6502\n",
      "\n",
      "Fold 2 test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1146\n",
      "           1       0.92      0.88      0.90      1343\n",
      "           2       0.85      0.84      0.84       475\n",
      "           3       0.88      0.87      0.88       529\n",
      "           4       0.74      0.85      0.79       356\n",
      "           5       0.63      0.86      0.73       151\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.82      0.86      0.84      4000\n",
      "weighted avg       0.88      0.87      0.88      4000\n",
      "\n",
      "Fold 3\n",
      "Fold 3 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1084\n",
      "           1       0.95      0.87      0.91      1083\n",
      "           2       0.95      0.94      0.95      1084\n",
      "           3       0.93      0.96      0.94      1084\n",
      "           4       0.91      0.98      0.94      1083\n",
      "           5       0.95      1.00      0.98      1084\n",
      "\n",
      "    accuracy                           0.94      6502\n",
      "   macro avg       0.94      0.94      0.94      6502\n",
      "weighted avg       0.94      0.94      0.94      6502\n",
      "\n",
      "Fold 3 test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      1146\n",
      "           1       0.91      0.88      0.89      1343\n",
      "           2       0.84      0.84      0.84       475\n",
      "           3       0.87      0.87      0.87       529\n",
      "           4       0.73      0.83      0.78       356\n",
      "           5       0.65      0.85      0.74       151\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.82      0.86      0.84      4000\n",
      "weighted avg       0.87      0.87      0.87      4000\n",
      "\n",
      "Fold 4\n",
      "Fold 4 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93      1084\n",
      "           1       0.94      0.88      0.91      1084\n",
      "           2       0.96      0.94      0.95      1083\n",
      "           3       0.94      0.96      0.95      1083\n",
      "           4       0.91      0.98      0.94      1083\n",
      "           5       0.96      1.00      0.98      1084\n",
      "\n",
      "    accuracy                           0.94      6501\n",
      "   macro avg       0.94      0.94      0.94      6501\n",
      "weighted avg       0.94      0.94      0.94      6501\n",
      "\n",
      "Fold 4 test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1146\n",
      "           1       0.91      0.88      0.90      1343\n",
      "           2       0.84      0.83      0.83       475\n",
      "           3       0.87      0.88      0.87       529\n",
      "           4       0.74      0.85      0.79       356\n",
      "           5       0.66      0.85      0.74       151\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.83      0.86      0.84      4000\n",
      "weighted avg       0.88      0.87      0.88      4000\n",
      "\n",
      "Fold 5\n",
      "Fold 5 validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1083\n",
      "           1       0.93      0.90      0.92      1084\n",
      "           2       0.95      0.94      0.94      1083\n",
      "           3       0.93      0.95      0.94      1083\n",
      "           4       0.93      0.97      0.95      1084\n",
      "           5       0.95      1.00      0.98      1084\n",
      "\n",
      "    accuracy                           0.94      6501\n",
      "   macro avg       0.94      0.94      0.94      6501\n",
      "weighted avg       0.94      0.94      0.94      6501\n",
      "\n",
      "Fold 5 test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1146\n",
      "           1       0.91      0.88      0.90      1343\n",
      "           2       0.84      0.82      0.83       475\n",
      "           3       0.87      0.87      0.87       529\n",
      "           4       0.75      0.83      0.79       356\n",
      "           5       0.65      0.86      0.74       151\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.82      0.86      0.84      4000\n",
      "weighted avg       0.88      0.87      0.87      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1)\n",
    "\n",
    "for i, (train_i, test_i) in enumerate(skf.split(train_df['text'], train_df['label'])):\n",
    "    print(f'Fold {i+1}')\n",
    "    text_train, text_validation = train_df['text'][train_i], train_df['text'][test_i]\n",
    "    label_train, label_validation = train_df['label'][train_i], train_df['label'][test_i]\n",
    "    text_test, label_test = test_df['text'], test_df['label']\n",
    "\n",
    "    # Create the model and train\n",
    "    logistic_regression = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LogisticRegression(max_iter=1000))])\n",
    "    logistic_regression.fit(text_train, label_train)\n",
    "    \n",
    "    # Evaluate the model on validation then test data\n",
    "    print(f\"Fold {i+1} validation:\")\n",
    "    print(classification_report(label_validation, logistic_regression.predict(text_validation)))\n",
    "    \n",
    "    print(f\"Fold {i+1} test:\")\n",
    "    print(classification_report(label_test, logistic_regression.predict(text_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run the model on a given piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_regression(text):\n",
    "    emotions = ['sadness', 'joy', 'fear', 'anger', 'love', 'surprise']\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model('./logistic_regression_model.keras')\n",
    "    processed_text = process_text(text)\n",
    "    prediction = model.predict([processed_text])\n",
    "    prediction = np.argmax(prediction)\n",
    "    return emotions[prediction]\n",
    "\n",
    "logistic_regression(\"im feeling a little cranky negative after this doctors appointment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
